# _Chapter1：NLP介绍_
&emsp;&emsp;自然语言处理(NLP)是当今世界理解和处理海量非结构化数据的重要工具。最近，深度学习已被广泛用于许多NLP任务，因为深度学习算法在诸如图像分类，语音识别和现实文本生成等过多的具有挑战性的任务中表现出显着的性能。反过来，TensorFlow是目前最直观，最有效的深度学习框架之一。本书将使有抱负的深度学习开发人员能够使用NLP和TensorFlow处理大量数据。 
&emsp;&emsp;在本章中，我们将介绍NLP以及本书的其余部分。我们将回答“什么是自然语言处理？”这一问题。此外，我们将介绍一些最重要的用途。我们还将考虑传统方法和最近基于深度学习的NLP方法，包括**全连接神经网络（FCNN）**。最后，我们将概述本书的其余部分以及我们将使用的技术工具。
## NLP是什么
&emsp;&emsp;根据IBM的数据，2017年每天都会生成2.5艾字节（1 exabyte = 1,000,000,000千兆字节）的数据，随着本书的编写，这种情况也在不断增加。从这个角度来看，如果世界上所有人都要处理这些数据，我们每个人每天处理的数据大约为300 MB。在所有这些数据中，很大一部分是非结构化文本和语音，因为每天都会创建数百万封电子邮件和社交媒体内容以及拨打电话。
&emsp;&emsp;这些统计数据为我们定义NLP提供了良好的基础。简而言之，NLP的目标是让机器理解我们的说出来的和写下来的语言。此外，NLP无处不在，已经成为人类生活的重要组成部分。**虚拟助手（VAs）**，例如Google Assistant，Cortana和Apple Siri，主要是NLP系统。当有人问VA时，会发生许多NLP任务，“你能告诉我一家附近不错的意大利餐馆吗？”首先，VA需要将话语转换为文本（即语音到文本）。接下来，它必须理解请求的语义（例如，用户正在寻找带有意大利美食的好餐厅）并制定结构化请求（例如，美食=意大利语，评级= 3-5，距离<10公里）。然后，VA必须搜索按位置和菜肴过滤的餐馆，然后按收到的评级对餐馆进行排序。为了计算餐馆的整体评级，一个优秀的NLP系统可以查看每个用户提供的评级和文本描述。最后，一旦用户在餐厅，VA可以通过将各种菜单项从意大利语翻译成英语来帮助用户。这个例子表明NLP已成为人类生活中不可或缺的一部分。  
&emsp;&emsp;应该理解，NLP是一个极具挑战性的研究领域，因为单词和语义具有高度复杂的非线性关系，并且将该信息捕获为鲁棒的数值表示更加困难。更糟糕的是，每种语言都有自己的语法，句式和词汇。因此，处理文本数据涉及各种复杂的任务，例如文本解析（例如，分词和词干提取）、词态分析、词义消歧、以及理解语言的基础语法结构。例如，在这两句话中，I went to the bank and I walked along the river bank，bank这个词有两个完全不同的含义。为了区分或（消除歧义）bank这个单词，我们需要理解单词的使用环境。机器学习已成为NLP的关键推动因素，有助于通过机器完成上述任务。
## NLP干什么
&emsp;&emsp;NLP拥有众多实际应用。一个好的NLP系统是执行许多NLP任务的系统。当你在Google上搜索今天的天气或使用谷歌翻译找出如何用法语说说“你好吗？”，你依赖NLP中的此类任务的子集。我们将在这里列出一些最基础的任务，本书涵盖了这些任务的大部分：  
* **分词**：分词是将文本集分离为原子单元（例如，单词）的任务。 虽然看似微不足道，但是分词是一项重要任务。 例如，在日语中，单词不以空格或标点符号分隔。
* **语义消歧（WSD）**：WSD的任务是识别单词的正确含义。例如，在句子中，The dog barked at the mail man, and Tree bark is sometimes used as a medicine，bark这个词有两个不同的含义。WSD对于诸如问答之类的任务至关重要。
* **命名实体辨别（NER）**：NER尝试从给定的文本主体或文本语料库中提取实体（例如，人，位置和组织）。例如，约翰在星期一在学校给玛丽两个苹果的句子，将转换为 ***约翰***（名字）在 ***星期一***（时间）给 ***学校***（组织）的 ***玛丽***（名字） ***两个***（数字）苹果。NER是信息检索和知识表达等领域的必修课。
* **词性（PoS）标注**：PoS标记是将单词标注各自词性的任务。它既可以是名词，动词，形容词，副词，介词等基本标签，也可以是专有名词，普通名词，短语动词，动词等。
* **句子概要分类**：句子或概要（例如，电影评论）分类具有许多用例，例如垃圾邮件检测，新闻文章分类（例如，政治，技术和体育）和产品评论评级（即正面或负面）。这是通过训练具有标记数据的分类模型（即，由人标注的具有正面或负面标签的评论）来实现的。
* **语言生成**：在语言生成中，学习模型（例如，神经网络）使用文本语料库（大量文本文档）进行训练，其预测随后的新文本。例如，语言生成可以通过使用现有的科幻故事进行训练来输出一个全新的科幻故事。
* **问答（QA）**：QA技术具有很高的商业价值，这些技术是聊天机器人和虚拟助手（例如Google Assistant和Apple Siri）的基础。许多公司已经采用聊天机器人来提供客户支持。聊天机器人可用于回答和解决直接的客户问题（例如，更改客户的每月移动计划），无需人工干预即可解决。 QA涉及NLP的许多其他方面，例如信息检索和知识表示。因此，所有这些都使得开发QA系统变得非常困难。
* **机器翻译（MT）**：MT是将句子/短语从源语言（例如，德语）转换为目标语言（例如，英语）的任务。 这是一项非常具有挑战性的任务，因为不同的语言具有高度不同的形态结构，这意味着它不是一对一的转换。 此外，语言之间的单词到单词关系可以是一对多，一对一，多对一或多对多。这被称为MT文献中的单词对齐问题。  
  
&emsp;&emsp;最后，为了开发一个可以帮助人们完成日常任务的系统（例如，VA或聊天机器人），许多这些任务需要一起执行。正如我们在上一个例子中看到的那样，用户问：“你能告诉我附近有一家不错的意大利餐馆吗？” 需要完成几个不同的NLP任务，例如语音到文本转换，语义和情感分析，问题回答和机器翻译。 在图1.1中，我们给出了不同类型的NLP任务的层级分类。我们首先有两大类：分析（分析现有文本）和生成（生成新文本）任务。 然后我们将分析分为三个不同的类别：句法（基于语言结构的任务），语义（基于意义的任务）和务实（难以解决的开放问题）：
![image](https://github.com/jiaojunming/Natural-Language-Processing-with-TensorFlow-CN/blob/master/image/ch1_1.jpg)
  
&emsp;&emsp;了解了NLP中的各种任务后，让我们继续了解如何在机器的帮助下解决这些任务。  
## NLP的传统解法
&emsp;&emsp;解决NLP的传统或经典方法是几个关键步骤的顺序流程，它是一种统计方法。当我们仔细研究传统的NLP学习模型时，我们将能够看到一系列不同的任务，例如通过删除不需要的数据来预处理数据，使用特征工程来获得文本数据的良好数值表示，学习通过训练数据使用机器学习算法，并预测新的不熟悉的数据。 其中，特征工程是在给定NLP任务上获得良好表现的最耗时且最关键的步骤。
### 理解经典解法
&emsp;&emsp;解决NLP任务的经典方法涉及一组不同的子任务。首先，需要对文本语料库进行预处理，重点是减少词汇量和 _干扰_。_干扰_ ，指的是干扰算法捕获任务所需的重要语言信息的东西（例如，标点符号和停止词删除）。  
&emsp;&emsp;接下来，介绍几个功能工程步骤。特征工程的主要目标是使算法的学习更容易。通常，这些特征是手工设计的，并且偏向于人类对语言的理解。特征工程对于经典NLP算法非常重要，因此，效果最佳的系统通常具有最佳工程特征。例如，对于情感分类任务 ，您可以使用解析树表示一个句子，并为树中的每个节点/子树分配正，负或中性标签，以将该句子分类为正或负。 此外，特征工程阶段可以使用外部资源（如WordNet（词汇数据库））来开发更好的特征。我们很快就会看到一种简单的特征工程技术，称为**词袋**。  
&emsp;&emsp;接下来，学习算法使用所获得的特征和可选的外部资源来学习在给定任务中表现良好。例如，对于文本摘要任务，包含单词同义词的同义词库可以是良好的外部资源。最后，预测发生。预测非常简单，提供新的输入并获得预测标签。经典方法的整个过程如图1.2所示：
![image](https://github.com/jiaojunming/Natural-Language-Processing-with-TensorFlow-CN/blob/master/image/ch1_2.jpg)
#### 例子：生成足球比赛摘要
&emsp;&emsp;为了深入理解传统的NLP方法，让我们考虑从足球比赛的统计数据中自动生成文本的任务。我们有几部分比赛统计数据（例如，得分，罚分和黄牌）以及由记者为比赛生成的相应文章作为训练数据。我们还假设对于给定的比赛，我们有从每个统计参数到该参数的摘要的最相关短语的映射。我们的任务是，在新比赛的基础上，我们需要生成一个关于比赛的自然总结。当然，这可以简单到从训练数据中找到新比赛的最佳匹配统计并检索相应的摘要。但是，有更复杂和优雅的文本生成方式。  
&emsp;&emsp;如果我们要将机器学习结合起来生成自然语言，则可能会执行一系列操作，例如预处理文本，分词，特征工程，训练和预测。   
&emsp;&emsp;**预处理**文本涉及很多操作，例如词干提取（例如，转换listened为listen）和删除标点符号（例如，！和;），以减少词汇量（即特征），从而减少内存需求。重要的是要明白词干提取不是一项微不足道的操作。可能看起来词干提取是一个简单的操作，它依赖于一系列简单的规则，例如从动词中删除ed（例如，listened的词干提取结果是listen）;但是，开发一个优秀的词干提取算法不仅仅是依赖一个简单的规则库，因为对某些特定词提取词干可能很棘手（例如，argued词干提取结果是argue）。此外，词干提取算法的效果可能因语言不同而差异很大。  
&emsp;&emsp;**分词**是可能需要执行的另一个预处理步骤。分词是将语料库划分为小实体（例如，单词）的过程。对于像英语这样的语言来说，这可能显得微不足道，因为这些词是分割的; 但是，对于某些语言（如泰语，日语和中文）而言，情况并非如此，因为这些语言并没有固有的划分。  
&emsp;&emsp;**特征工程**用于将原始文本数据转换为更吸引人的数字格式，因为模型可以基于这种数据格式进行训练，例如，将文本转换为词袋表示或使用n-gram表示（我们将在稍后讨论）。但是请记住，当今最先进的经典模型依赖于更复杂的特征工程技术。以下是几个特征工程技术：  
&emsp;&emsp; * 词袋：这是一种特征工程技术，可根据单词出现频率创建特征表示。 例如，让我们考虑以下句子：
